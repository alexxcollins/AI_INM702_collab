#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Nov 16 09:50:03 2021

@author: alexxcollins
"""

#!/usr/bin/env python3
# -- coding: utf-8 --
"""
Created on Thu Nov 11 12:01:05 2021

@author: alexxcollins
"""

#%% to test if I can create ABC which defintes how to generate y with x
from numpy.random import default_rng
from abc import ABC, abstractmethod
import numpy as np
import matplotlib.pyplot as plt 
from mpl_toolkits import mplot3d
from sklearn.linear_model import LinearRegression

np.random.seed(42)   #seems better to have seed here?
rng = np.random.default_rng()

class GenerateData(ABC):
    '''
    The base class will generate random Y given parameters for sample size
    beta (coefficients for intercept plus independent variables), variance of
    epsilon and optional X. 
    The X generated by this base class will match dimension of beta and will
    be generated from uniform distribution along each dimension. Subclasses can
    be used to generate or supply difference Xs, with outliers, co-depence etc.
    '''

    def _init(self, N=1000, beta=(1,2,3), noise_var=1): #typo corrected, should be _ instead of _
        # not sure where to set random seed. Should we do this in Jupyter notebook?
        # and pass into the class?
        self.rng = default_rng(42)
        self.N = N
        self._p = len(beta)-1
        self._p1 = len(beta)
        self.beta = np.array(beta).reshape((self._p1,1))
        # we often use p and p' in regression formulas, so I'm defining both
        # at the moment discourage changing with underscore rather than setters
        self.e_var = 1
        self.e = self._generate_epsilon()
        
    def _generate_epsilon(self):
        return self.rng.normal(0, self.e_var**(1/2), 
                               size=(self.N,1))
    
    @abstractmethod
    def generate_X(self, low=None, high=None):
        pass
    
    def generate_y(self):
        return np.matmul(self.X, self.beta) + self.e
    
    def generate_dataset(self):
        self.y = self.generate_y(self)
        
    # @property
    # def y(self):
    #     return self.generate_y()
    
            
class UniformX(GenerateData): #amended to have X as purely input data
    
    def generate_X(self, low=-10, high=10):
        self.X = rng.uniform(low=low, high=high, size=(self.N,self._p))
      

    def generate_y(self):
        return np.matmul(np.concatenate([np.ones((self.N,1)), self.X], axis=1), self.beta) + self.e
     
    
    def generate_dataset(self):
        self.y = self.generate_y()


class Outlier(GenerateData):
    
    def generate_X(self, original_X, original_y, original_beta, positions, magnitude):
        self.X = np.vstack((original_X,np.array((positions)))
        
    def generate_y(self):
        return np.vstack((original_y, magnitude + np.matmul(np.concatenate([np.ones((len(positions),1)), positions], axis=1), self.beta) ))
    
    def generate_dataset(self):
        self.y = self.generate_y()

        
def print_coef(X, y):
    reg = LinearRegression().fit(X, y)
    score=reg.score(X, y)
    coef=reg.coef_
    intercept=reg.intercept_
    print("intercept: "+str(intercept)+"; coef: "+str(coef))
    return     intercept, coef, score
#testing

test1=UniformX(100)
test1.generate_X()
test1.generate_y()
test1.generate_dataset()
plt.plot(test1.X, test1.y, 'o')
plt.show()

ax = plt.axes(projection='3d')
ax.scatter3D(test1.X[:,0].flatten(), test1.X[:,1].flatten(), test1.y, c=test1.y, cmap='Greens')

#add single outlier and test impact for different positions
set1=UniformX(1000)
set1.generate_X()
X=set1.X
y=set1.generate_y()
set1.generate_dataset()
print("set1 - ")
print_coef(set1.X, set1.y)


set1a_X=np.vstack((set1.X,np.array((10,10))))
set1a_y=np.vstack((set1.y, 500))
print("set1a -")
print_coef(set1a_X, set1a_y)

set1b_X=np.vstack((set1.X,np.array((0,0))))
set1b_y=np.vstack((set1.y, 500))
print("set1b -")
print_coef(set1b_X, set1b_y)

set1c_X=np.vstack((set1.X,np.array((-10,-10))))
set1c_y=np.vstack((set1.y, 500))
print("set1c -")
print_coef(set1c_X, set1c_y)

#test impact for negative direction
set2a_X=np.vstack((set1.X,np.array((10,10))))
set2a_y=np.vstack((set1.y, -500))
print("set2a -")
print_coef(set2a_X, set2a_y)

set2b_X=np.vstack((set1.X,np.array((0,0))))
set2b_y=np.vstack((set1.y, -500))
print("set2b -")
print_coef(set2b_X, set2b_y)

set2c_X=np.vstack((set1.X,np.array((-10,-10))))
set2c_y=np.vstack((set1.y, -500))
print("set2c -")
print_coef(set2c_X, set2c_y)

test3=Outlier(X, y, set1.beta, (10,10), 500)
test3.generate_X()
test3.generate_y()
test3.generate_dataset()
print("Outlier")
print_coef(test3.X, test3.y)

#vary number and magnitude of outliers...

#simulation function to build? use random part as function input?